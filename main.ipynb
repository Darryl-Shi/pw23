{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with Data (2023)\n",
    "## RQ1\n",
    "- bar chart (positive, neutral and negative)\n",
    "- word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: unrecognized arguments: supress output from this cell\n"
     ]
    }
   ],
   "source": [
    "%%capture # supress output from this cell\n",
    "\n",
    "# imports\n",
    "from afinn import Afinn\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk as nt\n",
    "import pandas as pd\n",
    "import wordcloud as wc\n",
    "\n",
    "# TODO: uncomment the following two lines for the first time you run this program!\n",
    "nt.download('punkt')\n",
    "nt.download('stopwords')\n",
    "\n",
    "# matplotlib things\n",
    "plt.figure(figsize=(3,6), dpi=60)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['font.family'] = ['Times New Roman', 'serif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# define some stopwords\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m stop \u001b[39m=\u001b[39m nt\u001b[39m.\u001b[39mcorpus\u001b[39m.\u001b[39mstopwords\u001b[39m.\u001b[39mwords(\u001b[39m'\u001b[39m\u001b[39menglish\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m$-@_.&+#!*\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m(),\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m?:\u001b[39m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m      4\u001b[0m \tstop\u001b[39m.\u001b[39mappend(i)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nt' is not defined"
     ]
    }
   ],
   "source": [
    "# define some stopwords\n",
    "stop = nt.corpus.stopwords.words('english')\n",
    "for i in '$-@_.&+#!*\\\\(),\\'\"?:%':\n",
    "\tstop.append(i)\n",
    "stop.append('n\\'t')\n",
    "\n",
    "# read the data\n",
    "data = pd.read_csv('./data/Datafiniti_Hotel_Reviews.csv', header=0, sep=',', on_bad_lines='skip')\n",
    "\n",
    "# extract the title and body text of each review into a large list\n",
    "bodies, titles = data['reviews.text'].astype(str), data['reviews.title'].astype(str)\n",
    "\n",
    "\"\"\"\n",
    "remove extraneous words that should not be analysed: \n",
    "remove \"... More\" from reviews (if it exists):\n",
    "\t\"... More\" (captured while web-scraping)\n",
    "\t\"Bad\", \"Good\" (those should not be affecting the sentiment calculated later)\n",
    "\"\"\"\n",
    "bodies = bodies.str.replace('((Bad|Good):)|(\\\\.\\\\.\\\\. More)', '', regex=True)\n",
    "\n",
    "# tokenise, remove stop words and puncutation\n",
    "bodies_tokens = (bodies.apply(nt.word_tokenize)).apply(lambda x: [token for token in x if token.lower() not in stop])\n",
    "\n",
    "# get a large array of all tokens to be analysed\n",
    "bodies_tokens_raw = []\n",
    "for bodies_sentence in bodies_tokens:\n",
    "\tfor bodies_token in bodies_sentence:\n",
    "\t\tbodies_tokens_raw.append(bodies_token)\n",
    "\n",
    "# create a list of tuples (token, sentiment)\n",
    "tokens_sentiments = []\n",
    "\n",
    "# sentiment analysis starts here.\n",
    "afn = Afinn()\n",
    "\n",
    "# loop through the tokens one by one, assign each word a score, then add it to the list.\n",
    "for token in bodies_tokens_raw:\n",
    "\ttokens_sentiments.append(tuple((token, afn.score(token))))\n",
    "\n",
    "# filter the sentiment data into three categories: positive, neutral and negative.\n",
    "sentiments_pos, sentiments_neg, sentiments_neu = [], [], []\n",
    "for token_sentiment in tokens_sentiments:\n",
    "\tif token_sentiment[1] > 0:\n",
    "\t\tsentiments_pos.append(token_sentiment)\n",
    "\telif token_sentiment[1] < 0:\n",
    "\t\tsentiments_neg.append(token_sentiment)\n",
    "\telse:\n",
    "\t\tsentiments_neu.append(token_sentiment)\n",
    "\n",
    "# generate a string of positive and negative tokens\n",
    "# these will be used for generating the wordclouds.\n",
    "tokens_pos = \"\".join(token_pos[0] + \" \" for token_pos in sentiments_pos)\n",
    "tokens_neg = \"\".join(token_neg[0] + \" \" for token_neg in sentiments_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a bar graph for bipartite sentiments (+ve, -ve)\n",
    "figure, axes = plt.subplots()\n",
    "bars_container = axes.bar(['Positive', 'Negative'], [len(sentiments_pos), len(sentiments_neg)])\n",
    "axes.set_title('Sentiments (Token-Based, Bipartite) from Hotel Reviews')\n",
    "axes.set_xlabel(\"Sentiment (Bipartite)\")\n",
    "axes.set_ylabel('Number of Tokens')\n",
    "axes.bar_label(bars_container, fmt=\"{:,.0f}\")\n",
    "plt.savefig(\"./results/rq1/bar_bipartite.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wordcloud (positive tokens)\n",
    "wordcloud = wc.WordCloud(background_color=\"white\", mode=\"RGB\", width=1280, height=720)\n",
    "wordcloud.generate(tokens_pos)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.title(\"Word Cloud: Positive Tokens\")\n",
    "plt.show()\n",
    "wordcloud.to_file(\"./results/rq1/wordcloud_pos.png\")\n",
    "\n",
    "# wordcloud (negative tokens)\n",
    "wordcloud.generate(tokens_neg)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis('off')\n",
    "plt.title(\"Word Cloud: Negative Tokens\")\n",
    "plt.show()\n",
    "wordcloud.to_file(\"./results/rq1/wordcloud_neg.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
